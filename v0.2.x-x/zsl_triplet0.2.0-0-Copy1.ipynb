{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T07:57:25.115423Z",
     "start_time": "2018-09-07T07:57:24.813129Z"
    },
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "from My_Loss import HardTripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T07:57:25.118267Z",
     "start_time": "2018-09-07T07:57:25.116391Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPISODE = 10000\n",
    "TEST_EPISODE = 1000\n",
    "LEARNING_RATE =1e-3\n",
    "GPU = 0\n",
    "Margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T07:57:27.224777Z",
     "start_time": "2018-09-07T07:57:25.119480Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"init dataset\")\n",
    "##################################参数##################################################################\n",
    "dataroot = '../data'\n",
    "dataset = 'AwA1_data'\n",
    "image_embedding = 'res101'               #ResNet101层\n",
    "class_embedding = 'original_att'         #属性表达 85-d\n",
    "#######################################读取视觉特征###################################################################\n",
    "\n",
    "matcontent = sio.loadmat(dataroot + \"/\" + dataset + \"/\" + image_embedding + \".mat\")  #scipy loadmat\n",
    " \n",
    "feature = matcontent['features'].T         #转置 30478x2048 每一行是一个完整的样本\n",
    "\n",
    "label = matcontent['labels'].astype(int).squeeze() - 1   #matlab begin 1 ,numpy begin 0\n",
    "########################################读取属性特征###########################################################\n",
    "\n",
    "matcontent = sio.loadmat(dataroot + \"/\" + dataset + \"/\" + class_embedding + \"_splits.mat\")\n",
    "\n",
    "    \n",
    "# numpy array index starts from 0, matlab starts from 1\n",
    "trainval_loc = matcontent['trainval_loc'].squeeze() - 1    #squeeze()去掉维度中的1 AxBx1 --->AxB\n",
    "\n",
    "test_seen_loc = matcontent['test_seen_loc'].squeeze() - 1\n",
    "test_unseen_loc = matcontent['test_unseen_loc'].squeeze() - 1\n",
    "\n",
    "attribute = matcontent['att'].T    #转置 50x85 每行是整个属性向量\n",
    "\n",
    "x = feature[trainval_loc]                      # train_features trainval里面是图片的编号 begin with 0 ，19832个\n",
    "train_label = label[trainval_loc].astype(int)  # train_label  int类型没变 每个图片的lable 19832个\n",
    "train_id = np.unique(train_label)\n",
    "\n",
    "att = attribute[train_label]                   # train attributes 每个图片的属性 19832个\n",
    "    \n",
    "x_test = feature[test_unseen_loc]                   # test_feature 5685个\n",
    "test_label = label[test_unseen_loc].astype(int)     # test_label   5685个\n",
    "\n",
    "x_test_seen = feature[test_seen_loc]                #test_seen_feature 4958个\n",
    "test_label_seen = label[test_seen_loc].astype(int)  # test_seen_label  4958个\n",
    "    \n",
    "test_id = np.unique(test_label)                     # test_id  10个类 ，unique去重\n",
    "att_pro = attribute[test_id]                        # test_attribute 每一类的属性向量 10x85\n",
    "\n",
    "# train set\n",
    "train_features = torch.from_numpy(x)   #np-->tensor\n",
    "#train_fearures_negative = torch.from_numpy(x_negative)\n",
    "\n",
    "sample_attributes=[]\n",
    "train_label = torch.from_numpy(train_label).unsqueeze(1) #每张图片的属性转化 ，unsqueeze(1)就是插入到第一维度 AxB维-->Ax1xB\n",
    "#train_negative_label = torch.from_numpy(x_negative_label).unsqueeze(1)\n",
    "# attributes\n",
    "all_attributes = np.array(attribute)  #所有50类属性转变为numpy数组???属性向量仍然用的numpy类型 没有转化为pytorch\n",
    "#print(all_attributes)\n",
    "    \n",
    "#print('-'*50)\n",
    "attributes = torch.from_numpy(attribute) \n",
    "#print(attribute)\n",
    "# test set\n",
    "\n",
    "test_features = torch.from_numpy(x_test)\n",
    "#print(test_features.shape)\n",
    "\n",
    "test_label = torch.from_numpy(test_label).unsqueeze(1)\n",
    "#print(test_label.shape)\n",
    "\n",
    "testclasses_id = np.array(test_id)\n",
    "#print(testclasses_id.shape)\n",
    "\n",
    "test_attributes = torch.from_numpy(att_pro).float()\n",
    "#print(test_attributes.shape)\n",
    "\n",
    "test_seen_features = torch.from_numpy(x_test_seen)\n",
    "#print(test_seen_features.shape)\n",
    "\n",
    "test_seen_label = torch.from_numpy(test_label_seen)\n",
    "\n",
    "train_data = TensorDataset( train_label, train_features )\n",
    "#train_data = TensorDataset(train_label, train_features, train_fearures_negative)\n",
    "\n",
    "#################here need new code to make triplet data#####################\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T07:57:27.227950Z",
     "start_time": "2018-09-07T07:57:27.225725Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttributeNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden1_size):\n",
    "        super(AttributeNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)   #FC1 network\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))      #activate\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T07:57:29.703580Z",
     "start_time": "2018-09-07T07:57:27.229759Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# init network\n",
    "print(\"init networks\")\n",
    "\n",
    "triplet_network = AttributeNetwork(85,2048)  #85d属性 1024隐藏层 2048输出 85d到2048d\n",
    "triplet_network.cuda(GPU)   \n",
    "\n",
    "triplet_network_optim = torch.optim.SGD(triplet_network.parameters(), lr=LEARNING_RATE)\n",
    "triplet_network_scheduler = StepLR(triplet_network_optim , step_size=100000 , gamma=0.5)\n",
    "#\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T07:57:29.709565Z",
     "start_time": "2018-09-07T07:57:29.704839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(test_features, test_label, test_id, test_attributes):\n",
    "    \n",
    "    test_data = TensorDataset(test_features, test_label)\n",
    "    test_batch = 32\n",
    "    test_loader = DataLoader(test_data, batch_size=test_batch, shuffle=False)\n",
    "    total_rewards = 0\n",
    "\n",
    "    sample_labels = test_id\n",
    "    sample_attributes = test_attributes\n",
    "    class_num = sample_attributes.shape[0]\n",
    "    test_size = test_features.shape[0]\n",
    "\n",
    "    print(\"class num:\", class_num)\n",
    "\n",
    "    for batch_features,batch_labels in test_loader:\n",
    "\n",
    "        batch_size = batch_labels.shape[0]\n",
    "        batch_features_ext = torch.from_numpy(batch_features.numpy().repeat(class_num, 0))\n",
    "        batch_features_ext = Variable(batch_features_ext).cuda(GPU).float()  # 32*1024\n",
    "\n",
    "        #print(batch_features_ext)\n",
    "\n",
    "        sample_features = triplet_network(Variable(sample_attributes).cuda(GPU).float())\n",
    "        sample_features_ext = sample_features.repeat(batch_size, 1)\n",
    "        #print(sample_features_ext.shape)\n",
    "\n",
    "\n",
    "        relations = F.pairwise_distance(batch_features_ext, sample_features_ext, 2).view(-1, class_num)\n",
    "        re_batch_labels = []\n",
    "        for label in batch_labels.numpy():\n",
    "            index = np.argwhere(sample_labels == label)\n",
    "            re_batch_labels.append(index[0][0])\n",
    "        re_batch_labels = torch.cuda.LongTensor(re_batch_labels)\n",
    "\n",
    "\n",
    "        _, predict_labels = torch.min(relations.data, 1)\n",
    "        #print(predict_labels)\n",
    "        rewards = [1 if predict_labels[j] == re_batch_labels[j] else 0 for j in range(batch_size)]\n",
    "        total_rewards += np.sum(rewards)\n",
    "    test_accuracy = total_rewards/1.0/test_size\n",
    "    return  test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T07:57:24.586Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"training...\")\n",
    "last_accuracy = 0.0\n",
    "for episode in range(EPISODE):\n",
    "    #attribute_network.train()\n",
    "    triplet_network_scheduler.step(episode)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    batch_labels, batch_features = train_loader.__iter__().next()\n",
    "    batch_id = np.unique(batch_labels)\n",
    "    #print('batch_id: ', batch_id)\n",
    "    #print('batch_id_size: ', batch_id.size)\n",
    "    #batch_attributes = torch.Tensor([all_attributes[i] for i in batch_labels.numpy()]).squeeze(1)\n",
    "    batch_attributes = torch.Tensor([all_attributes[i] for i in batch_id]).squeeze(1)\n",
    "    batch_features_ext = torch.from_numpy(batch_features.numpy().repeat(batch_id.size, 0))\n",
    "    batch_attributes_ext = batch_attributes.repeat(BATCH_SIZE, 1)\n",
    "    #print(batch_attributes.size()[0])\n",
    "    batch_features_ext = Variable(batch_features_ext).cuda(GPU).float()  # 32*2048\n",
    "    batch_attributes_ext = Variable(batch_attributes_ext).cuda(GPU)\n",
    "    #batch_features = Variable(batch_features)  # 32*2048\n",
    "    #batch_attributes = Variable(batch_attributes).cuda(GPU).float()\n",
    "    #print(batch_features_ext)\n",
    "    #print('-' * 100)\n",
    "    #relations = F.pairwise_distance(batch_features_ext,triplet_network(batch_attributes_ext),2).view(-1,batch_id.size)\n",
    "    #relations = _pairwise_distance(triplet_network(batch_attributes),batch_features)\n",
    "\n",
    "    re_batch_labels = []\n",
    "    for label in batch_labels.numpy():\n",
    "        index = np.argwhere(batch_id == label)\n",
    "        re_batch_labels.append(index[0][0])\n",
    "    re_batch_labels = torch.cuda.LongTensor(re_batch_labels)\n",
    "    re_batch_labels = Variable(re_batch_labels).cuda(GPU)\n",
    "    \n",
    "\n",
    "    criterion = HardTripletLoss(margin = Margin).cuda(GPU)\n",
    "    triplet_loss= criterion(triplet_network(batch_attributes_ext), batch_features_ext, re_batch_labels)\n",
    "    triplet_network.zero_grad()\n",
    "    triplet_loss.backward()\n",
    "    triplet_network_optim.step()\n",
    "    \n",
    "    if (episode+1)%1000 == 0:\n",
    "        print(\"episode:\", episode+1, \"loss\", triplet_loss.data)\n",
    "    if (episode+1)%1000 == 0:\n",
    "        print(\"Testing...\")\n",
    "        #attribute_network.eval()\n",
    "        zsl_accuracy = compute_accuracy(test_features, test_label, test_id, test_attributes)\n",
    "        gzsl_unseen_accuracy = compute_accuracy(test_features, test_label, np.arange(50), attributes)\n",
    "        gzsl_seen_accuracy = compute_accuracy(test_seen_features, test_seen_label, np.arange(50), attributes)\n",
    "        H = 2 * gzsl_seen_accuracy * gzsl_unseen_accuracy / (gzsl_unseen_accuracy + gzsl_seen_accuracy)\n",
    "        print('zsl:', zsl_accuracy)\n",
    "        print('gzsl: unseen=%.4f , seen=%.4f , h=%.4f' % (gzsl_unseen_accuracy , gzsl_seen_accuracy, H))\n",
    "        print('_'*100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-07T07:57:24.587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #print('relations.size: ', relations.size())\n",
    "    #print('re_batch_labels: ', re_batch_labels)\n",
    "    #mask_pos = torch.zeros_like(relations) \n",
    "    #for i in range(BATCH_SIZE):\n",
    "        #mask_pos[i][re_batch_labels[i]]=1   \n",
    "    #print(mask_pos)\n",
    "    #mask_pos=_get_anchor_positive_triplet_mask(relations, re_batch_labels)\n",
    "    #mask_neg=_get_anchor_negative_triplet_mask(relations, re_batch_labels)\n",
    "    #mask_neg = torch.ones_like(relations)\n",
    "    #print('-'*100)\n",
    "    #for i in range(BATCH_SIZE):\n",
    "        #mask_neg[i][re_batch_labels[i]]=0\n",
    "    #pos_batch=relations*mask_pos\n",
    "    #neg_batch=relations*mask_neg\n",
    "    #num_pos=torch.sum(mask_pos)\n",
    "    #num_neg=torch.sum(mask_neg)\n",
    "    #print('pos_number: ', num_pos)\n",
    "    #print('neg_number: ', num_neg)\n",
    "    #hardest_positive_dist, pos_labels = torch.max(pos_batch.data, 0)\n",
    "    #print(hardest_positive_dist.size(),'\\n', pos_labels)\n",
    "    #hardest_negative_dist, neg_labels = torch.min(neg_batch.data, 0)\n",
    "    #print(hardest_negative_dist.size(),'\\n', neg_labels)\n",
    "    #triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + Margin)\n",
    "    #triplet_loss = torch.mean(triplet_loss)\n",
    "    \n",
    "    #triplet_network.zero_grad()\n",
    "    #triplet_loss.backward()\n",
    "    #triplet_network_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
