{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:38:17.337275Z",
     "start_time": "2018-08-29T13:38:17.083006Z"
    },
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:38:17.344107Z",
     "start_time": "2018-08-29T13:38:17.338213Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPISODE = 500000\n",
    "TEST_EPISODE = 1000\n",
    "LEARNING_RATE =1e-5\n",
    "Nom = 1e-5\n",
    "Weight_Deacy =1e-5\n",
    "GPU = 0\n",
    "Margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:38:20.150740Z",
     "start_time": "2018-08-29T13:38:17.345800Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dataset\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"init dataset\")\n",
    "##################################参数##################################################################\n",
    "dataroot = '../data'\n",
    "dataset = 'AwA2_data'\n",
    "image_embedding = 'res101'               #ResNet101层\n",
    "class_embedding = 'att'         #属性表达 85-d\n",
    "#######################################读取视觉特征###################################################################\n",
    "\n",
    "matcontent = sio.loadmat(dataroot + \"/\" + dataset + \"/\" + image_embedding + \".mat\")  #scipy loadmat\n",
    " \n",
    "feature = matcontent['features'].T         #转置 30478x2048 每一行是一个完整的样本\n",
    "\n",
    "label = matcontent['labels'].astype(int).squeeze() - 1   #matlab begin 1 ,numpy begin 0\n",
    "########################################读取属性特征###########################################################\n",
    "\n",
    "matcontent = sio.loadmat(dataroot + \"/\" + dataset + \"/\" + class_embedding + \"_splits.mat\")\n",
    "\n",
    "    \n",
    "# numpy array index starts from 0, matlab starts from 1\n",
    "trainval_loc = matcontent['trainval_loc'].squeeze() - 1    #squeeze()去掉维度中的1 AxBx1 --->AxB\n",
    "\n",
    "test_seen_loc = matcontent['test_seen_loc'].squeeze() - 1\n",
    "test_unseen_loc = matcontent['test_unseen_loc'].squeeze() - 1\n",
    "\n",
    "attribute = matcontent['att'].T    #转置 50x85 每行是整个属性向量\n",
    "\n",
    "x = feature[trainval_loc]                      # train_features trainval里面是图片的编号 begin with 0 ，19832个\n",
    "train_label = label[trainval_loc].astype(int)  # train_label  int类型没变 每个图片的lable 19832个\n",
    "train_id = np.unique(train_label)\n",
    "\n",
    "att = attribute[train_label]                   # train attributes 每个图片的属性 19832个\n",
    "\n",
    "########################add negative pairs#######################\n",
    "#x_negative = np.empty_like(x)\n",
    "#x_negative_label = np.empty_like(train_label)\n",
    "#print(x.shape[0])\n",
    "\n",
    "#for i in range(x.shape[0]):\n",
    "#    pick=np.random.choice(np.where(train_label[i]!=train_id)[0], replace=True)\n",
    "#    x_negative[i] = x[pick]\n",
    "#    x_negative_label[i] = train_label[pick]\n",
    "    \n",
    "x_test = feature[test_unseen_loc]                   # test_feature 5685个\n",
    "test_label = label[test_unseen_loc].astype(int)     # test_label   5685个\n",
    "\n",
    "x_test_seen = feature[test_seen_loc]                #test_seen_feature 4958个\n",
    "test_label_seen = label[test_seen_loc].astype(int)  # test_seen_label  4958个\n",
    "    \n",
    "test_id = np.unique(test_label)                     # test_id  10个类 ，unique去重\n",
    "att_pro = attribute[test_id]                        # test_attribute 每一类的属性向量 10x85\n",
    "\n",
    "# train set\n",
    "train_features = torch.from_numpy(x)   #np-->tensor\n",
    "#train_fearures_negative = torch.from_numpy(x_negative)\n",
    "\n",
    "sample_attributes=[]\n",
    "train_label = torch.from_numpy(train_label).unsqueeze(1) #每张图片的属性转化 ，unsqueeze(1)就是插入到第一维度 AxB维-->Ax1xB\n",
    "#train_negative_label = torch.from_numpy(x_negative_label).unsqueeze(1)\n",
    "# attributes\n",
    "all_attributes = np.array(attribute)  #所有50类属性转变为numpy数组???属性向量仍然用的numpy类型 没有转化为pytorch\n",
    "#print(all_attributes)\n",
    "    \n",
    "#print('-'*50)\n",
    "attributes = torch.from_numpy(attribute) \n",
    "#print(attribute)\n",
    "# test set\n",
    "\n",
    "test_features = torch.from_numpy(x_test)\n",
    "#print(test_features.shape)\n",
    "\n",
    "test_label = torch.from_numpy(test_label).unsqueeze(1)\n",
    "#print(test_label.shape)\n",
    "\n",
    "testclasses_id = np.array(test_id)\n",
    "#print(testclasses_id.shape)\n",
    "\n",
    "test_attributes = torch.from_numpy(att_pro).float()\n",
    "#print(test_attributes.shape)\n",
    "\n",
    "test_seen_features = torch.from_numpy(x_test_seen)\n",
    "#print(test_seen_features.shape)\n",
    "\n",
    "test_seen_label = torch.from_numpy(test_label_seen)\n",
    "\n",
    "train_data = TensorDataset( train_label, train_features )\n",
    "#train_data = TensorDataset(train_label, train_features, train_fearures_negative)\n",
    "\n",
    "#################here need new code to make triplet data#####################\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:38:20.154703Z",
     "start_time": "2018-08-29T13:38:20.151963Z"
    },
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from my_net_2 import AttributeNetwork\n",
    "from my_net_2 import TripletNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:38:22.226391Z",
     "start_time": "2018-08-29T13:38:20.156401Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init networks\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# init network\n",
    "print(\"init networks\")\n",
    "attribute_network = AttributeNetwork(85,1024,1024,2048)  #85d属性 1024隐藏层 2048输出 85d到2048d\n",
    "triplet_network = TripletNetwork(attribute_network)  #metric learning   \n",
    "triplet_network.cuda(GPU)   \n",
    "#attribute_network_optim = torch.optim.Adam(attribute_network.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "#优化器adam 学习率 正则1e-5\n",
    "\n",
    "#attribute_network_scheduler = StepLR(attribute_network_optim, step_size=200000, gamma=0.5)\n",
    "#学习率每200k步 乘0.5\n",
    "#triplet_network_optim = torch.optim.Adam(triplet_network.parameters(), lr=LEARNING_RATE)\n",
    "#\n",
    "triplet_network_optim = torch.optim.Adam(triplet_network.parameters(), lr=LEARNING_RATE, \n",
    "                                         weight_decay=Weight_Deacy)\n",
    "triplet_network_scheduler = StepLR(triplet_network_optim , step_size=200000 , gamma=0.5)\n",
    "#\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:38:22.234747Z",
     "start_time": "2018-08-29T13:38:22.227472Z"
    },
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(test_features, test_label, test_id, test_attributes):\n",
    "    \n",
    "    test_data = TensorDataset(test_features, test_label)\n",
    "    test_batch = 32\n",
    "    test_loader = DataLoader(test_data, batch_size=test_batch, shuffle=False)\n",
    "    total_rewards = 0\n",
    "\n",
    "    sample_labels = test_id\n",
    "    sample_attributes = test_attributes\n",
    "    class_num = sample_attributes.shape[0]\n",
    "    test_size = test_features.shape[0]\n",
    "\n",
    "    print(\"class num:\", class_num)\n",
    "\n",
    "    for batch_features,batch_labels in test_loader:\n",
    "\n",
    "        batch_size = batch_labels.shape[0]\n",
    "        batch_features_ext = torch.from_numpy(batch_features.numpy().repeat(class_num, 0))\n",
    "        batch_features_ext = Variable(batch_features_ext).cuda(GPU).float()  # 32*1024\n",
    "\n",
    "        #print(batch_features_ext)\n",
    "\n",
    "        sample_features = attribute_network(Variable(sample_attributes).cuda(GPU).float())\n",
    "        sample_features_ext = sample_features.repeat(batch_size, 1)\n",
    "        #print(sample_features_ext.shape)\n",
    "\n",
    "\n",
    "        relations = F.pairwise_distance(batch_features_ext, sample_features_ext,2).view(-1, class_num)\n",
    "        re_batch_labels = []\n",
    "        for label in batch_labels.numpy():\n",
    "            index = np.argwhere(sample_labels == label)\n",
    "            re_batch_labels.append(index[0][0])\n",
    "        re_batch_labels = torch.cuda.LongTensor(re_batch_labels)\n",
    "\n",
    "\n",
    "        _, predict_labels = torch.min(relations.data, 1)\n",
    "        #print(predict_labels)\n",
    "        rewards = [1 if predict_labels[j] == re_batch_labels[j] else 0 for j in range(batch_size)]\n",
    "        total_rewards += np.sum(rewards)\n",
    "    test_accuracy = total_rewards/1.0/test_size\n",
    "    return  test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T13:47:59.865710Z",
     "start_time": "2018-08-29T13:38:22.236222Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "episode: 1000 loss tensor(2.3575, device='cuda:0')\n",
      "episode: 2000 loss tensor(1.7996, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.17945153544799697\n",
      "gzsl: unseen=0.0014 , seen=0.0388 , h=0.0027\n",
      "____________________________________________________________________________________________________\n",
      "episode: 3000 loss tensor(2.0915, device='cuda:0')\n",
      "episode: 4000 loss tensor(2.0640, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.17945153544799697\n",
      "gzsl: unseen=0.1279 , seen=0.0388 , h=0.0595\n",
      "____________________________________________________________________________________________________\n",
      "episode: 5000 loss tensor(2.1010, device='cuda:0')\n",
      "episode: 6000 loss tensor(1.5674, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.17945153544799697\n",
      "gzsl: unseen=0.0000 , seen=0.0388 , h=0.0000\n",
      "____________________________________________________________________________________________________\n",
      "episode: 7000 loss tensor(2.4690, device='cuda:0')\n",
      "episode: 8000 loss tensor(1.7919, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.2018197902186276\n",
      "gzsl: unseen=0.0021 , seen=0.0449 , h=0.0041\n",
      "____________________________________________________________________________________________________\n",
      "episode: 9000 loss tensor(2.0114, device='cuda:0')\n",
      "episode: 10000 loss tensor(2.0132, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.22140780993302162\n",
      "gzsl: unseen=0.0301 , seen=0.0853 , h=0.0445\n",
      "____________________________________________________________________________________________________\n",
      "episode: 11000 loss tensor(1.3992, device='cuda:0')\n",
      "episode: 12000 loss tensor(1.6725, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.1980285605964868\n",
      "gzsl: unseen=0.0566 , seen=0.0381 , h=0.0455\n",
      "____________________________________________________________________________________________________\n",
      "episode: 13000 loss tensor(1.5254, device='cuda:0')\n",
      "episode: 14000 loss tensor(1.7804, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.23404524200682422\n",
      "gzsl: unseen=0.0781 , seen=0.0699 , h=0.0738\n",
      "____________________________________________________________________________________________________\n",
      "episode: 15000 loss tensor(1.8525, device='cuda:0')\n",
      "episode: 16000 loss tensor(1.4390, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.27739163401996714\n",
      "gzsl: unseen=0.0695 , seen=0.1047 , h=0.0836\n",
      "____________________________________________________________________________________________________\n",
      "episode: 17000 loss tensor(1.5894, device='cuda:0')\n",
      "episode: 18000 loss tensor(1.3787, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.31644129912801716\n",
      "gzsl: unseen=0.1105 , seen=0.1081 , h=0.1093\n",
      "____________________________________________________________________________________________________\n",
      "episode: 19000 loss tensor(1.5399, device='cuda:0')\n",
      "episode: 20000 loss tensor(1.7522, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.34007329710602807\n",
      "gzsl: unseen=0.1163 , seen=0.1241 , h=0.1201\n",
      "____________________________________________________________________________________________________\n",
      "episode: 21000 loss tensor(1.5518, device='cuda:0')\n",
      "episode: 22000 loss tensor(1.4152, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.34891949955768986\n",
      "gzsl: unseen=0.1645 , seen=0.1250 , h=0.1420\n",
      "____________________________________________________________________________________________________\n",
      "episode: 23000 loss tensor(1.4843, device='cuda:0')\n",
      "episode: 24000 loss tensor(1.2942, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.37583722987488943\n",
      "gzsl: unseen=0.2722 , seen=0.1136 , h=0.1603\n",
      "____________________________________________________________________________________________________\n",
      "episode: 25000 loss tensor(1.4392, device='cuda:0')\n",
      "episode: 26000 loss tensor(1.2083, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.3854416782509794\n",
      "gzsl: unseen=0.2943 , seen=0.1148 , h=0.1651\n",
      "____________________________________________________________________________________________________\n",
      "episode: 27000 loss tensor(1.5079, device='cuda:0')\n",
      "episode: 28000 loss tensor(1.2118, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.39871098192847215\n",
      "gzsl: unseen=0.2917 , seen=0.1166 , h=0.1666\n",
      "____________________________________________________________________________________________________\n",
      "episode: 29000 loss tensor(1.3915, device='cuda:0')\n",
      "episode: 30000 loss tensor(1.7676, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.42348034879312524\n",
      "gzsl: unseen=0.3181 , seen=0.1227 , h=0.1771\n",
      "____________________________________________________________________________________________________\n",
      "episode: 31000 loss tensor(1.3146, device='cuda:0')\n",
      "episode: 32000 loss tensor(1.3356, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.4344749146973335\n",
      "gzsl: unseen=0.3399 , seen=0.1265 , h=0.1844\n",
      "____________________________________________________________________________________________________\n",
      "episode: 33000 loss tensor(1.1176, device='cuda:0')\n",
      "episode: 34000 loss tensor(1.0637, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.4344749146973335\n",
      "gzsl: unseen=0.3533 , seen=0.1299 , h=0.1900\n",
      "____________________________________________________________________________________________________\n",
      "episode: 35000 loss tensor(1.3020, device='cuda:0')\n",
      "episode: 36000 loss tensor(1.3871, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.436749652470618\n",
      "gzsl: unseen=0.3490 , seen=0.1431 , h=0.2030\n",
      "____________________________________________________________________________________________________\n",
      "episode: 37000 loss tensor(1.2107, device='cuda:0')\n",
      "episode: 38000 loss tensor(1.5920, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.44357386579047137\n",
      "gzsl: unseen=0.3469 , seen=0.1501 , h=0.2096\n",
      "____________________________________________________________________________________________________\n",
      "episode: 39000 loss tensor(1.4661, device='cuda:0')\n",
      "episode: 40000 loss tensor(1.0497, device='cuda:0')\n",
      "Testing...\n",
      "class num: 10\n",
      "class num: 50\n",
      "class num: 50\n",
      "zsl: 0.4450903576393277\n",
      "gzsl: unseen=0.3331 , seen=0.1532 , h=0.2099\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3dbd71ed5836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features_negative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbatch_features_negative\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpick\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mbatch_features_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/wanghai/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"training...\")\n",
    "last_accuracy = 0.0\n",
    "for episode in range(EPISODE):\n",
    "   \n",
    "    triplet_network_scheduler.step(episode)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    batch_labels, batch_features = train_loader.__iter__().next()\n",
    "    \n",
    "    batch_features_negative = np.empty_like(batch_features.numpy())\n",
    "    \n",
    "    batch_attributes = torch.Tensor([all_attributes[i] for i in batch_labels.numpy()]).squeeze(1)\n",
    "    \n",
    "    batch_features = Variable(batch_features).cuda(GPU).float()  # 32*2048\n",
    "    \n",
    "    for i in range(batch_features_negative.shape[0]):\n",
    "        pick=np.random.choice(np.where(batch_labels.numpy()!=batch_labels.numpy()[i])[0], replace=True)\n",
    "        batch_features_negative[i] = batch_features[pick]    \n",
    "    \n",
    "    batch_features_negative = torch.from_numpy(batch_features_negative)\n",
    "    batch_features_negative = Variable(batch_features_negative).cuda(GPU).float()  # 32*2048\n",
    "    \n",
    "    #batch_attributes = attribute_network(Variable(batch_attributes).cuda(GPU))\n",
    "    batch_attributes = Variable(batch_attributes).cuda(GPU)\n",
    "    \n",
    "    dista, distb, embedded_x, embedded_y, embedded_z = triplet_network(batch_attributes, batch_features, batch_features_negative)\n",
    "    \n",
    "    criterion = nn.MarginRankingLoss(margin = Margin).cuda(GPU)\n",
    "    \n",
    "    target = torch.FloatTensor(dista.size()).fill_(-1).cuda(GPU)\n",
    "    \n",
    "    \n",
    "    loss_triplet= criterion(dista, distb, target)\n",
    "    loss_embedd = embedded_x.norm(2) + embedded_y.norm(2) + embedded_z.norm(2)\n",
    "    loss = loss_triplet + Nom * loss_embedd\n",
    "\n",
    "    # update\n",
    "    triplet_network.zero_grad()\n",
    "    loss.backward()\n",
    "    triplet_network_optim.step()\n",
    "    \n",
    "    if (episode+1)%1000 == 0:\n",
    "        print(\"episode:\", episode+1, \"loss\", loss.data)\n",
    "    if (episode+1)%2000 == 0:\n",
    "        print(\"Testing...\")\n",
    "        zsl_accuracy = compute_accuracy(test_features, test_label, test_id, test_attributes)\n",
    "        gzsl_unseen_accuracy = compute_accuracy(test_features, test_label, np.arange(50), attributes)\n",
    "        gzsl_seen_accuracy = compute_accuracy(test_seen_features, test_seen_label, np.arange(50), attributes)\n",
    "        H = 2 * gzsl_seen_accuracy * gzsl_unseen_accuracy / (gzsl_unseen_accuracy + gzsl_seen_accuracy)\n",
    "        print('zsl:', zsl_accuracy)\n",
    "        print('gzsl: unseen=%.4f , seen=%.4f , h=%.4f' % (gzsl_unseen_accuracy , gzsl_seen_accuracy, H))\n",
    "        print('_'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
